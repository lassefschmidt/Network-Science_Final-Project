{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3f9796",
   "metadata": {},
   "source": [
    "# Machine Learning in Network Science\n",
    "Group Challenge\n",
    "\n",
    "***\n",
    "by: Leonardo Basili, Paul Bédier, Lasse Schmidt\n",
    "\n",
    "within: MS Data Sciences & Business Analytics\n",
    "\n",
    "at: CentraleSupélec & ESSEC Business School\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a46be5a",
   "metadata": {},
   "source": [
    "This notebook covers global graph feature extraction such as Rooted Pagerank and SimRank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f241a1",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e82605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.autoencoder' from '/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/autoencoder.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(analyseData)\n",
    "reload(prepData)\n",
    "reload(loadData)\n",
    "reload(modeling)\n",
    "reload(autoenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ffae4f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import own scripts\n",
    "import util.analyse_Data as analyseData\n",
    "import util.preprocess_Data as prepData\n",
    "import util.load_Data as loadData\n",
    "import util.modeling as modeling\n",
    "import util.autoencoder as autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stuff\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict\n",
    "\n",
    "# parse & handle data\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx # graph data\n",
    "import sknetwork\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfdac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive edges for training: 3802\n",
      "Number of positive edges for validation: 1085\n",
      "Number of positive edges for test: 542\n",
      "Number of edges in original graph: 5429\n",
      "Number of edges in training graph: 3802\n",
      "Number of non-existing edges generated: 29971\n",
      "Number of negative edges for training: 3802\n",
      "Number of negative edges for validation: 1085\n",
      "Number of negative edges for test: 542\n"
     ]
    }
   ],
   "source": [
    "(G, G_train, G_trainval, node_info, train_tf, val_tf, trainval_tf, test_tf) = loadData.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c682248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive edges for training: 3802\n",
      "Number of positive edges for validation: 1085\n",
      "Number of positive edges for test: 542\n",
      "Number of edges in original graph: 5429\n",
      "Number of edges in training graph: 3802\n",
      "Number of non-existing edges generated: 29971\n",
      "Number of negative edges for training: 3802\n",
      "Number of negative edges for validation: 1085\n",
      "Number of negative edges for test: 542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af1541576a542729c8c58f50c86ca6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/2708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:01<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriching train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/preprocess_Data.py:130: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G, nodelist = nodelist)\n",
      "/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/preprocess_Data.py:99: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G, nodelist = nodelist)\n",
      "/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/preprocess_Data.py:153: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G, nodelist = nodelist).toarray()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriching validation data...\n",
      "Enriching test data...\n"
     ]
    }
   ],
   "source": [
    "# might take up to a few minutes\n",
    "reload(analyseData)\n",
    "reload(prepData)\n",
    "reload(loadData)\n",
    "reload(modeling)\n",
    "reload(autoenc)\n",
    "(G, G_train, G_trainval, node_info,\n",
    " train_tf, val_tf, trainval_tf, test_tf,\n",
    " X_train, y_train, X_val, y_val, X_trainval, y_trainval,\n",
    " X_test, y_test) = loadData.load_transform(val_ratio = 0.2, test_ratio = 0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74f20e78",
   "metadata": {},
   "source": [
    "### 2. Rooted Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f6f3a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_save_rooted_pagerank_json(G, df, damp, eps, trainval_tf = False):\n",
    "    # create dictionary to store result\n",
    "    res = dict()\n",
    "\n",
    "    # compute rooted pagerank\n",
    "    pagerank = {root: prepData.rooted_pagerank(G, root, d = damp, epsilon = eps) for root in sorted(df.source.unique())}\n",
    "\n",
    "    # only store the edges we actually need in result dict\n",
    "    for u, v in zip(df.source, df.target):\n",
    "        res[str(u)+\"_\"+str(v)] = pagerank[u][v]\n",
    "\n",
    "    # save in json file\n",
    "    if trainval_tf:\n",
    "        fname = f\"rooted_pagerank_trainval_d{str(int(damp*100))}_eps{str(eps)}.json\"\n",
    "    else:\n",
    "        fname = f\"rooted_pagerank_test_d{str(int(damp*100))}_eps{str(eps)}.json\"\n",
    "\n",
    "    with open(\"data/\" + fname, \"w\") as file:\n",
    "        json.dump(res, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c29b24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nodeInfo_dupl  nodeInfo_diff  source_DCT  target_DCT      BCT_diff  \\\n",
      "0              0             38    0.001108    0.001847  2.866839e-06   \n",
      "0              0             26    0.001847    0.001108 -1.822490e-05   \n",
      "1              0             37    0.001108    0.001108  8.190967e-07   \n",
      "1              0             41    0.001108    0.001847  1.795187e-05   \n",
      "2              0             33    0.001108    0.002216  1.228645e-06   \n",
      "\n",
      "   katz_idx  sim_rank  root_pagerank  node2vec_1  node2vec_2  node2vec_3  \\\n",
      "0       0.0       0.0            0.0    0.000004    0.254515    0.070102   \n",
      "0       0.0       0.0            0.0    1.296436    0.799854    0.164829   \n",
      "1       0.0       0.0            0.0    0.001248    0.038168    0.000728   \n",
      "1       0.0       0.0            0.0    2.122296    1.059141    0.082487   \n",
      "2       0.0       0.0            0.0    0.000330    0.000312    0.002599   \n",
      "\n",
      "   node2vec_4  friendLink       PR1           PR2  \n",
      "0    0.142970         0.0  0.000407  5.812262e-09  \n",
      "0    0.067303         0.0  0.000411  6.033748e-08  \n",
      "1    0.019172         0.0  0.000432  7.416656e-10  \n",
      "1    0.000002         0.0  0.000498  5.276121e-09  \n",
      "2    0.000628         0.0  0.000429  1.088221e-09  \n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77d4e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pagerank using damp 0.5 and eps 0.0001...\n",
      "Computing pagerank using damp 0.5 and eps 1e-06...\n",
      "Computing pagerank using damp 0.75 and eps 0.0001...\n",
      "Computing pagerank using damp 0.75 and eps 1e-06...\n",
      "Computing pagerank using damp 0.9 and eps 0.0001...\n",
      "Computing pagerank using damp 0.9 and eps 1e-06...\n",
      "Computing pagerank using damp 0.95 and eps 0.0001...\n",
      "Computing pagerank using damp 0.95 and eps 1e-06...\n",
      "Computing pagerank using damp 0.99 and eps 0.0001...\n",
      "Computing pagerank using damp 0.99 and eps 1e-06...\n"
     ]
    }
   ],
   "source": [
    "# search space\n",
    "dampening_facts = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "eps = [1e-4, 1e-6]\n",
    "\n",
    "# create rooted page rank using different hyperparams\n",
    "for damp in dampening_facts:\n",
    "    for e in eps:\n",
    "        print(f\"Computing pagerank using damp {damp} and eps {e}...\")\n",
    "\n",
    "        # trainval edges\n",
    "        compute_save_rooted_pagerank_json(G_train, trainval_tf, damp = damp, eps = e, trainval_tf = True)\n",
    "\n",
    "        # test edges\n",
    "        compute_save_rooted_pagerank_json(G, test_tf, damp = damp, eps = e, trainval_tf = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "056959e1",
   "metadata": {},
   "source": [
    "Let us now find the best hyperparameters of our rooted pagerank by validating each of them with our supervised model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d13eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of the files\n",
    "fnames_trainval, fnames_test = [], []\n",
    "\n",
    "# used search space\n",
    "dampening_facts = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "eps = [1e-4, 1e-6]\n",
    "\n",
    "# get names\n",
    "for damp in dampening_facts:\n",
    "    for e in eps:\n",
    "        fnames_trainval.append(f\"data/rooted_pagerank_trainval_d{str(int(damp*100))}_eps{str(e)}.json\")\n",
    "        fnames_test.append(f\"data/rooted_pagerank_test_d{str(int(damp*100))}_eps{str(e)}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d8ec1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(df, cols, method, thresh):\n",
    "    # we assume that all metrics get better with increasing values!\n",
    "    df_ = df[list(cols)]\n",
    "    if method == \"rank_avg\":\n",
    "        df_ = df_.rank(pct = True).mean(axis = 1)  \n",
    "    elif method == \"avg\":\n",
    "        df_ = df_.mean(axis = 1)\n",
    "    elif method == \"whitened_sigmoid_avg\":\n",
    "        df_ = pd.DataFrame({col: sknetwork.linkpred.whitened_sigmoid(df_[col].to_numpy()) for col in df_.columns})\n",
    "        df_ = df_.mean(axis = 1)\n",
    "        \n",
    "    if thresh == \"top50%\":\n",
    "        y_hat = (df_ > df_.median()).astype(int)\n",
    "    elif thresh == \"thresh\":\n",
    "        y_hat = (df_ > 0.5).astype(int)\n",
    "    elif thresh == \"return_probas\":\n",
    "        y_hat = df_.rank(pct = True)\n",
    "        \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa7373df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('root_pagerank',), ('sim_rank',), ('root_pagerank', 'sim_rank')]\n"
     ]
    }
   ],
   "source": [
    "print(sampled_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "695a304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wl/zfv53bfx13j4zx15j58_cby00000gn/T/ipykernel_1580/298633820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mval_acc\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0my_test_hat\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mtst_acc\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"trn_acc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrn_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_acc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtst_acc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wl/zfv53bfx13j4zx15j58_cby00000gn/T/ipykernel_1580/2845277016.py\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(df, cols, method, thresh)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# we assume that all metrics get better with increasing values!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rank_avg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "# where we will store result\n",
    "res = OrderedDict()\n",
    "\n",
    "# search space\n",
    "dampening_facts = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "eps = [1e-4, 1e-6]\n",
    "\n",
    "# create rooted page rank using different hyperparams\n",
    "for (trainval, test, (damp, e)) in zip(fnames_trainval, fnames_test, product(dampening_facts, eps)):\n",
    "\n",
    "    # read json files for rank algorithms\n",
    "    with open(trainval, \"r\") as file:\n",
    "        r_pgr_trainval = json.load(file)\n",
    "    with open(test, \"r\") as file:\n",
    "        r_pgr_test = json.load(file)\n",
    "\n",
    "    def read_pagerank_json(json, u, v):\n",
    "        key = str(u)+\"_\"+str(v)\n",
    "        if key in json.keys():\n",
    "            return json[key]\n",
    "\n",
    "    # append to dataframes\n",
    "    train_tf = train_tf.assign(root_pagerank = lambda df_: [read_pagerank_json(r_pgr_trainval, u, v) for u, v in zip(df_.source, df_.target)])\n",
    "    val_tf = val_tf.assign(root_pagerank = lambda df_: [read_pagerank_json(r_pgr_trainval, u, v) for u, v in zip(df_.source, df_.target)])\n",
    "    test_tf  = test_tf.assign(root_pagerank = lambda df_: [read_pagerank_json(r_pgr_test, u, v) for u, v in zip(df_.source, df_.target)])\n",
    "\n",
    "    # which cols we want to use for link prediction\n",
    "    cols = [\"root_pagerank\"]\n",
    "\n",
    "    methods = [\"rank_avg\"]\n",
    "    threshs = [\"thresh\"]\n",
    "\n",
    "    # generate all combinations of columns in cols\n",
    "    sampled_cols = []\n",
    "    for n in range(1, len(cols) + 1):\n",
    "        sampled_cols += list([c for c in combinations(cols, n)])\n",
    "\n",
    "    for s, m, t in tqdm(product(sampled_cols, methods, threshs)):\n",
    "        y_train_hat = compute_score(X_train, s, m, t)\n",
    "        y_val_hat   = compute_score(X_val, s, m, t)\n",
    "        trn_acc     = accuracy_score(y_train, y_train_hat)\n",
    "        val_acc     = accuracy_score(y_val, y_val_hat)\n",
    "        \n",
    "        y_test_hat  = compute_score(X_test, s, m, t)\n",
    "        tst_acc     = accuracy_score(test_tf.y, y_test_hat)\n",
    "        res[(s, m, t, damp, e)] = {\"trn_acc\": trn_acc, \"val_acc\": val_acc, \"test_acc\": tst_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2df74050",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_res = (sorted(res.items(), key = lambda kv: kv[1][\"val_acc\"], reverse = True))\n",
    "\n",
    "for (col, m, t, damp, e), val_dict in ordered_res[0:30]:\n",
    "    print(f\"using {damp}, {e}, {col}, {m}, {t}\")\n",
    "    print(f\"Train Accuracy {round(val_dict['trn_acc'], 5)}, Val Accuracy {round(val_dict['val_acc'], 5)}, Test Accuracy {round(val_dict['test_acc'], 5)} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "197ac983",
   "metadata": {},
   "source": [
    "Apparently hyperparam tuning of pagerank has absolutely no influence on overall score. When investigating the files, it is clear that the pagerank values change quite a lot -- but the global ordering of the pagerank scores of the edges is kept."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eecae55",
   "metadata": {},
   "source": [
    "### 3. SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a785877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simrank on G and G_train for each node\n",
    "simrank_test, simrank_trainval = prepData.get_simrank(G, G_train, test_tf, trainval_tf)\n",
    "\n",
    "# save resulting dictionaries in json files\n",
    "with open(\"data/simrank_trainval.json\", \"w\") as file:\n",
    "    json.dump(simrank_trainval, file)\n",
    "with open(\"data/simrank_test.json\", \"w\") as file:\n",
    "    json.dump(simrank_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01b6e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank_test, pagerank_trainval = prepData.get_simrank(G, G_train, test_tf, trainval_tf)\n",
    "\n",
    "# save resulting dictionaries in json files\n",
    "with open(\"data/pagerank_trainval.json\", \"w\") as file:\n",
    "    json.dump(pagerank_trainval, file)\n",
    "with open(\"data/pagerank_test.json\", \"w\") as file:\n",
    "    json.dump(pagerank_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d854d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.official_Data as officialData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead07185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "enriched_test = officialData.enrich_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9250ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_test_tf = pd.merge(test_tf, enriched_test, how = \"left\", on = [\"node1\", \"node2\"])\n",
    "y_col = enriched_test_tf.pop(\"y\")\n",
    "enriched_test_tf.insert(2, \"y\", y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b6b0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1748\n",
       "1    1733\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_test_tf.y.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "edc5d5641674580b35290ba45bd16007251669062615a59c5f9a5e5dd7884ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
