{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3f9796",
   "metadata": {},
   "source": [
    "# Machine Learning in Network Science\n",
    "Group Challenge\n",
    "\n",
    "***\n",
    "by: Leonardo Basili, Paul Bédier, Lasse Schmidt\n",
    "\n",
    "within: MS Data Sciences & Business Analytics\n",
    "\n",
    "at: CentraleSupélec & ESSEC Business School\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a46be5a",
   "metadata": {},
   "source": [
    "This notebook covers classical unsupervised link prediction techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f241a1",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e82605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.autoencoder' from '/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/autoencoder.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(analyseData)\n",
    "reload(prepData)\n",
    "reload(loadData)\n",
    "reload(modeling)\n",
    "reload(autoenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ffae4f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import own scripts\n",
    "import util.analyse_Data as analyseData\n",
    "import util.preprocess_Data as prepData\n",
    "import util.load_Data as loadData\n",
    "import util.modeling as modeling\n",
    "import util.autoencoder as autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stuff\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict\n",
    "\n",
    "# parse & handle data\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx # graph data\n",
    "import sknetwork\n",
    "\n",
    "# modeling\n",
    "import torch\n",
    "from torch_geometric.nn import GAE, VGAE\n",
    "from xgboost import XGBClassifier\n",
    "import sknetwork\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84a352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matplotlib and seaborn settings for nicer plots\n",
    "%matplotlib inline\n",
    "\n",
    "SMALL_SIZE = 6\n",
    "MEDIUM_SIZE = 8\n",
    "BIGGER_SIZE = 10\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f20e78",
   "metadata": {},
   "source": [
    "### 2. Load Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c682248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive edges for training: 3802\n",
      "Number of positive edges for validation: 1085\n",
      "Number of positive edges for test: 542\n",
      "Number of edges in original graph: 5429\n",
      "Number of edges in training graph: 3802\n",
      "Number of non-existing edges generated: 29971\n",
      "Number of negative edges for training: 3802\n",
      "Number of negative edges for validation: 1085\n",
      "Number of negative edges for test: 542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11038e1c71148b387e1fa7a1e2129e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/2708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:01<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriching train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/preprocess_Data.py:130: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G, nodelist = nodelist)\n",
      "/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/preprocess_Data.py:99: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G, nodelist = nodelist)\n",
      "/Users/macbookpro/Documents/GitHub/Network-Science_Final-Project/util/preprocess_Data.py:153: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(G, nodelist = nodelist).toarray()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriching validation data...\n",
      "Enriching test data...\n"
     ]
    }
   ],
   "source": [
    "# might take up to a few minutes\n",
    "(G, G_train, G_trainval, node_info,\n",
    " train_tf, val_tf, trainval_tf, test_tf,\n",
    " X_train, y_train, X_val, y_val, X_trainval, y_trainval,\n",
    " X_test, y_test) = loadData.load_transform(val_ratio = 0.2, test_ratio = 0.1, n2v_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3f7777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive edges for training: 3802\n",
      "Number of positive edges for validation: 1085\n",
      "Number of positive edges for test: 542\n",
      "Number of edges in original graph: 5429\n",
      "Number of edges in training graph: 3802\n",
      "Number of non-existing edges generated: 29971\n",
      "Number of negative edges for training: 3802\n",
      "Number of negative edges for validation: 1085\n",
      "Number of negative edges for test: 542\n",
      "sum of train pos edges: 3802\n",
      "sum of train neg edges: 3802\n",
      "sum of val pos edges: 1085\n",
      "sum of val neg edges: 1085\n",
      "sum of train pos edges: 3802\n",
      "sum of train neg edges: 3802\n",
      "sum of val pos edges: 1085\n",
      "sum of val neg edges: 1085\n",
      "Enriching node features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7796e39baa164869afdbdc69d6b3a7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/2708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 12.03it/s]\n",
      "/Users/macbookpro/Library/Python/3.9/lib/python/site-packages/networkx/algorithms/link_analysis/hits_alg.py:78: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G, nodelist=list(G), dtype=float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaaabb4dc9c4bcfbd7e18a12e3768cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/2708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create PyTorch Geometric dataset...\n"
     ]
    }
   ],
   "source": [
    "# might take up to a minute\n",
    "data, _ = autoenc.load(val_ratio = 0.2, test_ratio = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a785877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get node embeddings (IF YOU CHANGE SEED = 42, then you need to train new autoencoder as train-val split is different)\n",
    "\n",
    "# load best autoencoder\n",
    "path = os.path.abspath(\"\")+\"/models/VGNAE_0.001_0_4c954_00000_autoencoder.pt\"\n",
    "model = VGAE(autoenc.Encoder(data.x.size()[1], 64, 1.2, 5, 0.2, 0))\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "\n",
    "# get embeddings of nodes\n",
    "embedding = autoenc.get_embeddings(model, data.x, data.trainval_edges)\n",
    "node_emb = pd.DataFrame(embedding).rename(columns = {val: f\"x{val+1}\" for val in range(embedding.shape[1])})\n",
    "\n",
    "# enrich train\n",
    "train_sim = pd.DataFrame(autoenc.get_similarity(model, data.x, data.train_pos_edges, data.train_edges)).rename(columns = {0: \"sim\"})\n",
    "train_tf = (train_tf\n",
    "    .assign(sim = train_sim.sim.values)\n",
    "    .assign(sim_scaled = (train_sim.sim.values - train_sim.sim.values.min()) / (train_sim.sim.values.max() - train_sim.sim.values.min()))\n",
    "    .assign(dist = lambda df_: [np.linalg.norm(node_emb.loc[u].values-node_emb.loc[v].values) for u, v in zip(df_.source, df_.target)])\n",
    ")\n",
    "\n",
    "# enrich val\n",
    "val_sim = pd.DataFrame(autoenc.get_similarity(model, data.x, data.train_pos_edges, data.val_edges)).rename(columns = {0: \"sim\"})\n",
    "val_tf = (val_tf\n",
    "    .assign(sim = val_sim.sim.values)\n",
    "    .assign(sim_scaled = (val_sim.sim.values - val_sim.sim.values.min()) / (val_sim.sim.values.max() - val_sim.sim.values.min()))\n",
    "    .assign(dist = lambda df_: [np.linalg.norm(node_emb.loc[u].values-node_emb.loc[v].values) for u, v in zip(df_.source, df_.target)])\n",
    ")\n",
    "\n",
    "# enrich test\n",
    "test_sim = pd.DataFrame(autoenc.get_similarity(model, data.x, data.trainval_pos_edges, data.test_edges)).rename(columns = {0: \"sim\"})\n",
    "test_tf = (test_tf\n",
    "    .assign(sim = test_sim.sim.values)\n",
    "    .assign(sim_scaled = (test_sim.sim.values - test_sim.sim.values.min()) / (test_sim.sim.values.max() - test_sim.sim.values.min()))\n",
    "    .assign(dist = lambda df_: [np.linalg.norm(node_emb.loc[u].values-node_emb.loc[v].values) for u, v in zip(df_.source, df_.target)])\n",
    ")\n",
    "\n",
    "# split\n",
    "X_train, y_train = loadData.split_frame(train_tf)\n",
    "X_val, y_val     = loadData.split_frame(val_tf)\n",
    "X_test           = loadData.split_frame(test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242bc6d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot() got an unexpected keyword argument 'text_kw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wl/zfv53bfx13j4zx15j58_cby00000gn/T/ipykernel_95034/100273484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot correlation with target (first train, then validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_tf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0manalyseData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_corr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Network-Science_Final-Project/util/analyse_Data.py\u001b[0m in \u001b[0;36mplot_corr_matrix\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    172\u001b[0m     cm = ConfusionMatrixDisplay(corr_matrix,\n\u001b[1;32m    173\u001b[0m                                 display_labels = labels)\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks_rotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'vertical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fontsize\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelrotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot() got an unexpected keyword argument 'text_kw'"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;31m# kwarg-specified metadata gets precedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0m_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDisplayHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transient'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     display_pub.publish(\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36mpublish\u001b[0;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         self.session.send(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         \u001b[0mto_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0mto_send\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mlongest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_send\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, msg, ident)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;31m# content is already packed, as in a relayed message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mjson_packer\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjson_packer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     return jsonapi.dumps(\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/zmq/utils/jsonapi.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(o, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'separators'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/simplejson/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, use_decimal, namedtuple_as_object, tuple_as_array, bigint_as_string, sort_keys, item_sort_key, for_json, ignore_nan, int_as_string_bitcount, iterable_as_array, **kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     return cls(\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mskipkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ascii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/simplejson/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/simplejson/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 self.iterable_as_array, Decimal=decimal.Decimal)\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mkey_memo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/simplejson/encoder.py\u001b[0m in \u001b[0;36mencode_basestring\u001b[0;34m(s, _PY3, _q)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_PY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# convert an str subclass instance to exact str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "# plot correlation with target (first train, then validation)\n",
    "for df in [train_tf, val_tf]:\n",
    "    analyseData.plot_corr_matrix(df.iloc[:, 2:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "345c4898",
   "metadata": {},
   "source": [
    "### 3. Unsupervised Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92770a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(df, cols, method, thresh):\n",
    "    # we assume that all metrics get better with increasing values!\n",
    "    \n",
    "    df_ = df[list(cols)]\n",
    "    \n",
    "    if method == \"rank_avg\":\n",
    "        df_ = df_.rank(pct = True).mean(axis = 1)  \n",
    "    elif method == \"avg\":\n",
    "        df_ = df_.mean(axis = 1)\n",
    "    elif method == \"whitened_sigmoid_avg\":\n",
    "        df_ = pd.DataFrame({col: sknetwork.linkpred.whitened_sigmoid(df_[col].to_numpy()) for col in df_.columns})\n",
    "        df_ = df_.mean(axis = 1)\n",
    "        \n",
    "    if thresh == \"top50%\":\n",
    "        y_hat = (df_ > df_.median()).astype(int)\n",
    "    elif thresh == \"thresh\":\n",
    "        y_hat = (df_ > 0.5).astype(int)\n",
    "    elif thresh == \"return_probas\":\n",
    "        y_hat = df_.rank(pct = True)\n",
    "        \n",
    "    return y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f044c68",
   "metadata": {},
   "source": [
    "We only consider a subset of somewhat decorrelated metrics (otherwise this search will run too long). For example, Sorensen Index is highly correlated (.99) with Salton Index, thus it is enough to only include one of them in our below search (same for Adamic Adar and Resource Allocation, but not for Adamic Adar and SCF Resource Allocation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfbd10ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1482it [00:05, 262.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# which cols we want to use for link prediction\n",
    "res = OrderedDict()\n",
    "#removed from columns \"CNC\", \"SCF_RA\", \"JCC\", \"AA\", \"PA_log\",\n",
    "cols = [\"SoI\", \"HProm\", # local methods\n",
    "        \"katz_idx\", \"sim_rank\", \"root_pagerank\", \"node2vec_1\", \"node2vec_4\", # global methods\n",
    "        \"friendLink\"]                                           # quasi-local methods\n",
    "\n",
    "methods = [\"rank_avg\", \"avg\", \"whitened_sigmoid_avg\"]\n",
    "threshs = [\"top50%\", \"thresh\"]\n",
    "\n",
    "# generate all combinations of columns in cols\n",
    "sampled_cols = []\n",
    "for n in range(2, len(cols) + 1):\n",
    "    sampled_cols += list([c for c in combinations(cols, n)])\n",
    "\n",
    "for s, m, t in tqdm(product(sampled_cols, methods, threshs)):\n",
    "    y_train_hat = compute_score(X_train, s, m, t)\n",
    "    y_val_hat   = compute_score(X_val, s, m, t)\n",
    "    trn_acc     = accuracy_score(y_train, y_train_hat)\n",
    "    val_acc     = accuracy_score(y_val, y_val_hat)\n",
    "\n",
    "    res[(s, m, t)] = {\"trn_acc\": trn_acc, \"val_acc\": val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c653e94a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ('SoI', 'HProm', 'katz_idx', 'node2vec_4'), rank_avg, thresh\n",
      "Train Accuracy 0.68898, Val Accuracy 0.72396\n",
      "\n",
      "using ('SoI', 'HProm', 'node2vec_4', 'friendLink'), rank_avg, thresh\n",
      "Train Accuracy 0.66399, Val Accuracy 0.72396\n",
      "\n",
      "using ('SoI', 'HProm', 'katz_idx', 'sim_rank', 'root_pagerank', 'node2vec_4'), rank_avg, thresh\n",
      "Train Accuracy 0.6924, Val Accuracy 0.7235\n",
      "\n",
      "using ('SoI', 'HProm', 'sim_rank', 'root_pagerank', 'node2vec_4', 'friendLink'), rank_avg, thresh\n",
      "Train Accuracy 0.67438, Val Accuracy 0.7235\n",
      "\n",
      "using ('SoI', 'HProm', 'katz_idx', 'sim_rank', 'root_pagerank', 'node2vec_4', 'friendLink'), rank_avg, thresh\n",
      "Train Accuracy 0.69398, Val Accuracy 0.7235\n",
      "\n",
      "using ('SoI', 'HProm', 'node2vec_4'), rank_avg, thresh\n",
      "Train Accuracy 0.65637, Val Accuracy 0.72304\n",
      "\n",
      "using ('SoI', 'HProm', 'katz_idx', 'sim_rank', 'node2vec_4'), rank_avg, thresh\n",
      "Train Accuracy 0.69214, Val Accuracy 0.72304\n",
      "\n",
      "using ('SoI', 'HProm', 'katz_idx', 'root_pagerank', 'node2vec_4'), rank_avg, thresh\n",
      "Train Accuracy 0.69214, Val Accuracy 0.72304\n",
      "\n",
      "using ('SoI', 'HProm', 'katz_idx', 'node2vec_4', 'friendLink'), rank_avg, thresh\n",
      "Train Accuracy 0.6899, Val Accuracy 0.72304\n",
      "\n",
      "using ('SoI', 'HProm', 'sim_rank', 'node2vec_4', 'friendLink'), rank_avg, thresh\n",
      "Train Accuracy 0.67031, Val Accuracy 0.72304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordered_res = (sorted(res.items(), key = lambda kv: kv[1][\"val_acc\"], reverse = True))\n",
    "\n",
    "for (col, m, t), val_dict in ordered_res[0:10]:\n",
    "    print(f\"using {col}, {m}, {t}\")\n",
    "    print(f\"Train Accuracy {round(val_dict['trn_acc'], 5)}, Val Accuracy {round(val_dict['val_acc'], 5)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c31c2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best settings\n",
    "s = ['SoI', 'HProm', 'katz_idx', 'node2vec_4']\n",
    "m = \"rank_avg\"\n",
    "t = \"thresh\"\n",
    "y_train_hat = compute_score(X_train, s, m, t)\n",
    "y_val_hat   = compute_score(X_val, s, m, t)\n",
    "y_test_hat  = compute_score(X_test, s, m, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb761f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      3802\n",
      "           1       0.73      0.60      0.66      3802\n",
      "\n",
      "    accuracy                           0.69      7604\n",
      "   macro avg       0.69      0.69      0.69      7604\n",
      "weighted avg       0.69      0.69      0.69      7604\n",
      "\n",
      "Validation performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      1085\n",
      "           1       0.77      0.64      0.70      1085\n",
      "\n",
      "    accuracy                           0.72      2170\n",
      "   macro avg       0.73      0.72      0.72      2170\n",
      "weighted avg       0.73      0.72      0.72      2170\n",
      "\n",
      "Roc_auc score\n",
      "-------------------------------------------------------\n",
      "0.723963133640553\n",
      "\n",
      "Confusion matrix\n",
      "-------------------------------------------------------\n",
      "[[880 205]\n",
      " [394 691]]\n"
     ]
    }
   ],
   "source": [
    "# detailed performance analysis\n",
    "print('Train performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_train, y_train_hat))\n",
    "\n",
    "print('Validation performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_val, y_val_hat))\n",
    "\n",
    "print('Roc_auc score')\n",
    "print('-------------------------------------------------------')\n",
    "print(roc_auc_score(y_val, y_val_hat))\n",
    "print('')\n",
    "\n",
    "print('Confusion matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(confusion_matrix(y_val, y_val_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b639816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test predictions\n",
    "save_test = modeling.save_test_preds(test_tf[['source', 'target']], test_tf, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f12dad34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted\n",
       "0            648\n",
       "1            436\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at predicted labels\n",
    "save_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afcb40",
   "metadata": {},
   "source": [
    "let us now combine our local ensemble model with the embedding similarities from our autoencoder\n",
    "\n",
    "doesn't really work well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ad588ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's try to average these predictions with the results from our autoencoder\n",
    "#removed 'JCC', 'AA', 'PA_log',\n",
    "s = ['root_pagerank']\n",
    "m = \"rank_avg\"\n",
    "t = \"return_probas\"\n",
    "y_train_hat = compute_score(X_train, s, m, t)\n",
    "y_val_hat   = compute_score(X_val, s, m, t)\n",
    "y_test_hat  = compute_score(X_test, s, m, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daf3a11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'source', 'y', 'train_mask', 'val_mask', 'nodeInfo_dupl',\n",
       "       'nodeInfo_diff', 'source_DCT', 'target_DCT', 'BCT_diff', 'SaI', 'SoI',\n",
       "       'HProm', 'HDem', 'katz_idx', 'sim_rank', 'root_pagerank', 'node2vec_1',\n",
       "       'node2vec_2', 'node2vec_3', 'node2vec_4', 'friendLink', 'PR1', 'PR2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fc2a41f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wl/zfv53bfx13j4zx15j58_cby00000gn/T/ipykernel_95034/4211694518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# take max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_train_hat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_train_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_val_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_val_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sim'"
     ]
    }
   ],
   "source": [
    "# take max\n",
    "#understand where is sim\n",
    "y_train_hat = pd.concat([y_train_hat, train_tf.sim.rank(pct = True)], axis = 1).max(axis = 1)\n",
    "y_train_hat = (y_train_hat > y_train_hat.median()).astype(int)\n",
    "\n",
    "y_val_hat = pd.concat([y_val_hat, val_tf.sim.rank(pct = True)], axis = 1).max(axis = 1)\n",
    "y_val_hat = (y_val_hat > y_val_hat.median()).astype(int)\n",
    "\n",
    "y_test_hat = pd.concat([y_test_hat, test_tf.sim.rank(pct = True)], axis = 1).max(axis = 1)\n",
    "y_test_hat = (y_test_hat > y_test_hat.median()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b3511c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wl/zfv53bfx13j4zx15j58_cby00000gn/T/ipykernel_95034/740520139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbeta\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_train_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_train_hat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_train_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_train_hat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_train_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sim'"
     ]
    }
   ],
   "source": [
    "# add scaled similarities\n",
    "alpha = 0.66\n",
    "beta  = 0.34\n",
    "\n",
    "y_train_hat = (alpha * y_train_hat + beta * train_tf.sim.rank(pct = True))\n",
    "y_train_hat = (y_train_hat > y_train_hat.median()).astype(int)\n",
    "\n",
    "y_val_hat = (alpha * y_val_hat + beta * val_tf.sim.rank(pct = True))\n",
    "y_val_hat = (y_val_hat > y_val_hat.median()).astype(int)\n",
    "\n",
    "y_test_hat = (alpha * y_test_hat + beta * test_tf.sim.rank(pct = True))\n",
    "y_test_hat = (y_test_hat > y_test_hat.median()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f63103ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      4198\n",
      "           1       0.79      0.79      0.79      4174\n",
      "\n",
      "    accuracy                           0.79      8372\n",
      "   macro avg       0.79      0.79      0.79      8372\n",
      "weighted avg       0.79      0.79      0.79      8372\n",
      "\n",
      "Validation performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1050\n",
      "           1       0.76      0.76      0.76      1043\n",
      "\n",
      "    accuracy                           0.76      2093\n",
      "   macro avg       0.76      0.76      0.76      2093\n",
      "weighted avg       0.76      0.76      0.76      2093\n",
      "\n",
      "Roc_auc score\n",
      "-------------------------------------------------------\n",
      "0.7596772131671461\n",
      "\n",
      "Confusion matrix\n",
      "-------------------------------------------------------\n",
      "[[797 253]\n",
      " [250 793]]\n"
     ]
    }
   ],
   "source": [
    "# detailed performance analysis\n",
    "print('Train performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_train, y_train_hat))\n",
    "\n",
    "print('Validation performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_val, y_val_hat))\n",
    "\n",
    "print('Roc_auc score')\n",
    "print('-------------------------------------------------------')\n",
    "print(roc_auc_score(y_val, y_val_hat))\n",
    "print('')\n",
    "\n",
    "print('Confusion matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(confusion_matrix(y_val, y_val_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "edc5d5641674580b35290ba45bd16007251669062615a59c5f9a5e5dd7884ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
